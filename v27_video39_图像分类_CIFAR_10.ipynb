{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7fc76ad-eda4-4d0e-ae9e-32f0e4cb881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import utils\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc3210f4-1337-41e8-8abb-7b6b4efd39f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(r'../data/cifar-10')\n",
    "img_train_dir = data_dir / 'train'\n",
    "img_test_dir = data_dir / 'test'\n",
    "train_labels_csv = data_dir / 'trainLabels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb0d2040-bf80-4eee-82f9-69ed24c3c466",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "    'airplane': 0,\n",
    "    'automobile': 1,\n",
    "    'bird': 2,\n",
    "    'cat': 3,\n",
    "    'deer': 4,\n",
    "    'dog': 5,\n",
    "    'frog': 6,\n",
    "    'horse': 7,\n",
    "    'ship': 8,\n",
    "    'truck': 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40885c95-709e-47b4-8145-15d57a487d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>frog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>deer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>automobile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       label\n",
       "0   1        frog\n",
       "1   2       truck\n",
       "2   3       truck\n",
       "3   4        deer\n",
       "4   5  automobile"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_df = pd.read_csv(train_labels_csv.as_posix())\n",
    "train_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "895abece-7c4f-47b8-a613-965c640ce903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1      6\n",
       "1   2      9\n",
       "2   3      9\n",
       "3   4      4\n",
       "4   5      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_df['label'] = train_labels_df['label'].apply(lambda x: class_mapping[x])\n",
    "train_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8d40e90-5ece-43ee-a2ee-94298bd8393b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 9, 9, 4, 1, 1, 2, 7, 8, 3]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = train_labels_df['label'].values.tolist()\n",
    "train_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "835a3774-c546-48ad-9652-168bfc57455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "        cifar-10数据集\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir: Path, transforms=None, is_train=True):\n",
    "        \"\"\"\n",
    "            data_dir: 数据集目录\n",
    "            data_csv: 数据-类对应文件\n",
    "            transforms：数据增广\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.transforms = transforms\n",
    "        self.is_train = is_train\n",
    "        self.data_list = self.read_data()\n",
    "        \n",
    "    def read_data(self):\n",
    "        \"\"\"\n",
    "            读取数据\n",
    "        \"\"\"\n",
    "        return [img_path for img_path in self.data_dir.iterdir()]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # print(self.data_list[i])\n",
    "        img_path = self.data_list[i]\n",
    "        img = Image.open(img_path.as_posix()).convert('RGB')\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)          \n",
    "        if self.is_train:\n",
    "            img_id = int(img_path.stem)\n",
    "            label = train_labels[img_id-1]\n",
    "            return img, label     \n",
    "        return img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1e03ef8-3b33-4077-91de-002702ff9f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用RGB通道的均值和标准差，以标准化每个通道\n",
    "normalize = torchvision.transforms.Normalize(\n",
    "    [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "train_augs = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(size=(128, 128)),\n",
    "    torchvision.transforms.RandomResizedCrop(size=(112, 112), scale=(0.64, 1), ratio=(0.8, 1.2)),\n",
    "    torchvision.transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    normalize])\n",
    "\n",
    "test_augs = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(size=(112, 112)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e62322f-d06a-44a3-8a79-7e3209ba35af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_all = CifarDataset(img_train_dir, transforms=train_augs)\n",
    "test_dataset = CifarDataset(img_test_dir, transforms=test_augs, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49d67b85-9969-4b4c-9fab-65ab7e52a5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset_len = int(len(train_dataset_all) / 10)\n",
    "train_dataset_len = len(train_dataset_all) - valid_dataset_len\n",
    "\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(\n",
    "    dataset=train_dataset_all,\n",
    "    lengths=[train_dataset_len, valid_dataset_len],\n",
    "    generator=torch.Generator().manual_seed(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "408cde6e-c819-442a-9c70-cc365378f68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = torchvision.models.resnet34(pretrained=True)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eddd0d47-39a2-4f85-ad5a-8211e8354879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自定义fc层，将最终的输出类别设置为当前需要的10\n",
    "# net.fc = nn.Sequential(\n",
    "#     OrderedDict(\n",
    "#         [('fc', nn.Linear(net.fc.in_features, 512)),\n",
    "#          ('relu', nn.ReLU(inplace=True)),\n",
    "#          ('fc2', nn.Linear(512, 10))]\n",
    "#     )\n",
    "# )\n",
    "# nn.init.xavier_uniform_(net.fc.fc.weight);\n",
    "# nn.init.xavier_uniform_(net.fc.fc2.weight);\n",
    "\n",
    "net.fc = nn.Linear(net.fc.in_features, 256)\n",
    "net = nn.Sequential(\n",
    "    OrderedDict(\n",
    "        [('resnet', net),\n",
    "         ('relu', nn.ReLU(inplace=True)),\n",
    "         ('fc', nn.Linear(256, 10))]\n",
    "    )\n",
    ")\n",
    "nn.init.xavier_uniform_(net.resnet.fc.weight);\n",
    "nn.init.xavier_uniform_(net.fc.weight);\n",
    "\n",
    "# net.fc = nn.Linear(net.fc.in_features, 512)\n",
    "# net.add_module('relu2', nn.ReLU(inplace=True))\n",
    "# net.add_module('fc2', nn.Linear(512, 10))\n",
    "# nn.init.xavier_uniform_(net.fc.weight);\n",
    "# nn.init.xavier_uniform_(net.fc2.weight);\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b8303af-a3b9-4f15-a289-820ccf4d8470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试网络畅通\n",
    "random_x = torch.randn(size=[1, 3, 112, 112])\n",
    "random_y = net(random_x)\n",
    "random_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6299a9fc-30c2-4e30-b076-573aabae6838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果param_group=True，输出层中的模型参数将使用十倍的学习率\n",
    "def train_fine_tuning(net, learning_rate, batch_size=128, num_epochs=5, weight_decay=1e-3, \n",
    "                      fc_lr_times=10, param_group=True, freeze=False, train_all_data=False):\n",
    "    devices = utils.try_all_gpus()\n",
    "    loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "    if freeze:\n",
    "        for name, param in net.named_parameters():\n",
    "            if name not in [\"resnet.fc.weight\", \"resnet.fc.bias\", \"fc.weight\", \"fc.bias\"]:\n",
    "                param.requires_grad = False\n",
    "    if param_group:\n",
    "        params_1x = [param for name, param in net.named_parameters()\n",
    "             if name not in [\"resnet.fc.weight\", \"resnet.fc.bias\", \"fc.weight\", \"fc.bias\"]]\n",
    "        trainer = torch.optim.SGD(\n",
    "            [\n",
    "                {'params': params_1x}, \n",
    "                {'params': net.fc.parameters(), \n",
    "                 'lr': learning_rate * fc_lr_times}\n",
    "            ], \n",
    "            lr=learning_rate, \n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "    else:\n",
    "        trainer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    if train_all_data:\n",
    "        train_iter = torch.utils.data.DataLoader(\n",
    "            train_dataset_all, batch_size=batch_size, shuffle=True)\n",
    "        valid_iter = None\n",
    "    else:\n",
    "        train_iter = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        valid_iter = torch.utils.data.DataLoader(\n",
    "            valid_dataset, batch_size=batch_size)\n",
    "    utils.train_gpus(net, train_iter, valid_iter, loss, trainer, num_epochs, devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1f3e804-d3bb-495d-9dd5-dcf75fa5b565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1/5 ---\n",
      "training on: [device(type='cuda', index=0)], [2024-06-13 01:00:41]\n",
      "epoch: 1/6, loss 0.655, train acc 0.781, test acc 0.892\n",
      "epoch: 2/6, loss 0.273, train acc 0.907, test acc 0.912\n",
      "epoch: 3/6, loss 0.212, train acc 0.927, test acc 0.923\n",
      "epoch: 4/6, loss 0.181, train acc 0.938, test acc 0.936\n",
      "epoch: 5/6, loss 0.155, train acc 0.947, test acc 0.936\n",
      "epoch: 6/6, loss 0.136, train acc 0.953, test acc 0.936\n",
      "*** 430.1 examples/sec on [device(type='cuda', index=0)] - [0:00:10:27], all: [0:00:21:20] ***\n",
      "--- 2/5 ---\n",
      "training on: [device(type='cuda', index=0)], [2024-06-13 01:22:00]\n",
      "epoch: 1/6, loss 0.121, train acc 0.958, test acc 0.942\n",
      "epoch: 2/6, loss 0.103, train acc 0.964, test acc 0.942\n",
      "epoch: 3/6, loss 0.101, train acc 0.965, test acc 0.940\n",
      "epoch: 4/6, loss 0.088, train acc 0.969, test acc 0.946\n",
      "epoch: 5/6, loss 0.081, train acc 0.972, test acc 0.945\n",
      "epoch: 6/6, loss 0.073, train acc 0.974, test acc 0.947\n",
      "*** 433.0 examples/sec on [device(type='cuda', index=0)] - [0:00:10:23], all: [0:00:21:24] ***\n",
      "--- 3/5 ---\n",
      "training on: [device(type='cuda', index=0)], [2024-06-13 01:43:24]\n",
      "epoch: 1/6, loss 0.066, train acc 0.977, test acc 0.945\n",
      "epoch: 2/6, loss 0.062, train acc 0.979, test acc 0.946\n",
      "epoch: 3/6, loss 0.058, train acc 0.980, test acc 0.943\n",
      "epoch: 4/6, loss 0.051, train acc 0.983, test acc 0.950\n",
      "epoch: 5/6, loss 0.046, train acc 0.985, test acc 0.948\n",
      "epoch: 6/6, loss 0.048, train acc 0.983, test acc 0.950\n",
      "*** 432.3 examples/sec on [device(type='cuda', index=0)] - [0:00:10:24], all: [0:00:21:27] ***\n",
      "--- 4/5 ---\n",
      "training on: [device(type='cuda', index=0)], [2024-06-13 02:04:52]\n",
      "epoch: 1/6, loss 0.042, train acc 0.985, test acc 0.952\n",
      "epoch: 2/6, loss 0.039, train acc 0.987, test acc 0.949\n",
      "epoch: 3/6, loss 0.036, train acc 0.988, test acc 0.949\n",
      "epoch: 4/6, loss 0.034, train acc 0.988, test acc 0.950\n",
      "epoch: 5/6, loss 0.032, train acc 0.989, test acc 0.949\n",
      "epoch: 6/6, loss 0.033, train acc 0.989, test acc 0.949\n",
      "*** 434.2 examples/sec on [device(type='cuda', index=0)] - [0:00:10:21], all: [0:00:21:12] ***\n",
      "--- 5/5 ---\n",
      "training on: [device(type='cuda', index=0)], [2024-06-13 02:26:05]\n",
      "epoch: 1/6, loss 0.032, train acc 0.990, test acc 0.957\n",
      "epoch: 2/6, loss 0.027, train acc 0.991, test acc 0.955\n",
      "epoch: 3/6, loss 0.027, train acc 0.991, test acc 0.955\n",
      "epoch: 4/6, loss 0.025, train acc 0.992, test acc 0.952\n",
      "epoch: 5/6, loss 0.022, train acc 0.993, test acc 0.953\n",
      "epoch: 6/6, loss 0.022, train acc 0.993, test acc 0.953\n",
      "*** 444.3 examples/sec on [device(type='cuda', index=0)] - [0:00:10:07], all: [0:00:20:53] ***\n"
     ]
    }
   ],
   "source": [
    "train_times = 5\n",
    "for i in range(train_times):\n",
    "    print(f'--- {i+1}/{train_times} ---')\n",
    "    # 训练模型\n",
    "    train_fine_tuning(net, learning_rate=5e-5, batch_size=256, num_epochs=6, \n",
    "                      weight_decay=1e-3, fc_lr_times=10)\n",
    "    # 保存训练好的模型weight\n",
    "    save_model_path = Path(fr'../data/cifar_resnet34_state_dict_{i+1}.sd')\n",
    "    torch.save(net.state_dict(), save_model_path.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f4789a2-1299-4bc4-aa00-7a20c1d91879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on: [device(type='cuda', index=0)], [2024-06-13 07:59:55]\n",
      "epoch: 1/10, loss 0.035, train acc 0.989, test acc 0.000\n",
      "epoch: 2/10, loss 0.034, train acc 0.989, test acc 0.000\n",
      "epoch: 3/10, loss 0.031, train acc 0.990, test acc 0.000\n",
      "epoch: 4/10, loss 0.030, train acc 0.990, test acc 0.000\n",
      "epoch: 5/10, loss 0.029, train acc 0.991, test acc 0.000\n",
      "epoch: 6/10, loss 0.028, train acc 0.991, test acc 0.000\n",
      "epoch: 7/10, loss 0.027, train acc 0.991, test acc 0.000\n",
      "epoch: 8/10, loss 0.027, train acc 0.992, test acc 0.000\n",
      "epoch: 9/10, loss 0.025, train acc 0.992, test acc 0.000\n",
      "epoch: 10/10, loss 0.025, train acc 0.992, test acc 0.000\n",
      "*** 433.0 examples/sec on [device(type='cuda', index=0)] - [0:00:19:14], all: [0:00:41:29] ***\n"
     ]
    }
   ],
   "source": [
    "# 调整学习率、权重衰减等参数，多次学习调整\n",
    "train_fine_tuning(net, learning_rate=1e-5, batch_size=256, num_epochs=10, \n",
    "                  weight_decay=1e-3, fc_lr_times=10, train_all_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fae8aa58-0a9d-47a1-bd86-7e84c60744df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i = 6\n",
    "save_model_path = Path(fr'../data/cifar_resnet34_state_dict_{model_i}.sd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11067381-a485-4f34-b3ad-be2dd7ee9c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存训练好的模型weight\n",
    "torch.save(net.state_dict(), save_model_path.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9db2c6d8-dd94-46e0-a1c0-89d0b0795bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=256, bias=True)\n",
       "  )\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载训练好的模型\n",
    "net = None\n",
    "devices = utils.try_all_gpus()\n",
    "# 加载模型参数state_dict\n",
    "net = torchvision.models.resnet34()\n",
    "# 自定义fc层，将最终的输出类别设置为当前需要的10\n",
    "net.fc = nn.Linear(net.fc.in_features, 256)\n",
    "net = nn.Sequential(\n",
    "    OrderedDict(\n",
    "        [('resnet', net),\n",
    "         ('relu', nn.ReLU(inplace=True)),\n",
    "         ('fc', nn.Linear(256, 10))]\n",
    "    )\n",
    ")\n",
    "\n",
    "net.load_state_dict(torch.load(save_model_path.as_posix()))\n",
    "# net.to(torch.device('cpu'))\n",
    "net.to(devices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf6a1713-15b2-43b3-8633-ce03db6f0236",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "batch_size = 256\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54eb76b2-667d-429a-a814-f14902b047a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = torch.Tensor([], device=torch.device('cpu'))\n",
    "y_hat_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab60c6c7-2bac-41ce-b936-435130fd853d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300000])\n"
     ]
    }
   ],
   "source": [
    "for i, X in enumerate(test_iter):\n",
    "    # X = X.to(torch.device('cpu'))\n",
    "    X = X.to(devices[0])\n",
    "    y_hat = net(X)\n",
    "    y_hat = y_hat.to(torch.device('cpu'))\n",
    "    y_hat = y_hat.argmax(axis=1)\n",
    "    y_hat_list.append(y_hat)\n",
    "    print(i, i * batch_size + len(y_hat), end='\\r')\n",
    "y_all = torch.cat([*y_hat_list], dim=0)\n",
    "print(y_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "581e72db-ceb8-49f5-acd5-08073bd44d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 3, 2, 4, 6, 3, 4, 0, 6, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86cf626a-c552-4960-93b8-474722926ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'airplane',\n",
       " '1': 'automobile',\n",
       " '2': 'bird',\n",
       " '3': 'cat',\n",
       " '4': 'deer',\n",
       " '5': 'dog',\n",
       " '6': 'frog',\n",
       " '7': 'horse',\n",
       " '8': 'ship',\n",
       " '9': 'truck'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_mapping_reverse = dict()\n",
    "for k, v in class_mapping.items():\n",
    "    class_mapping_reverse[str(v)] = k\n",
    "class_mapping_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a834ecc-90f8-4861-bcb9-abf63d1bab0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deer',\n",
       " 'cat',\n",
       " 'bird',\n",
       " 'deer',\n",
       " 'frog',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'airplane',\n",
       " 'frog',\n",
       " 'automobile']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all_mapping_list = list()\n",
    "for i in y_all:\n",
    "    i_num = i.item()\n",
    "    i_mapping = class_mapping_reverse.get(str(i_num))\n",
    "    y_all_mapping_list.append(i_mapping)\n",
    "y_all_mapping_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3449e10a-fc2d-4972-86a8-eb5dcf978fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('../data/cifar-10/test/1.png'),\n",
       " WindowsPath('../data/cifar-10/test/10.png'),\n",
       " WindowsPath('../data/cifar-10/test/100.png'),\n",
       " WindowsPath('../data/cifar-10/test/1000.png'),\n",
       " WindowsPath('../data/cifar-10/test/10000.png'),\n",
       " WindowsPath('../data/cifar-10/test/100000.png'),\n",
       " WindowsPath('../data/cifar-10/test/100001.png'),\n",
       " WindowsPath('../data/cifar-10/test/100002.png'),\n",
       " WindowsPath('../data/cifar-10/test/100003.png'),\n",
       " WindowsPath('../data/cifar-10/test/100004.png')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.data_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5effbac7-496c-4140-af9f-0e708aed72bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id_list = list()\n",
    "for img_path in test_dataset.data_list:\n",
    "    img_id = img_path.stem\n",
    "    img_id_list.append(int(img_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "386eceb0-93ad-4a0d-b248-0a88fe25149f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>deer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>deer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>frog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id label\n",
       "0      1  deer\n",
       "1     10   cat\n",
       "2    100  bird\n",
       "3   1000  deer\n",
       "4  10000  frog"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_data = {\n",
    "    'id': img_id_list,\n",
    "    'label': y_all_mapping_list\n",
    "}\n",
    "y_df = pd.DataFrame(submission_data)\n",
    "y_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d343c4f2-c45d-410c-b652-b3ec77b69548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>deer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111111</th>\n",
       "      <td>2</td>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222222</th>\n",
       "      <td>3</td>\n",
       "      <td>automobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233334</th>\n",
       "      <td>4</td>\n",
       "      <td>ship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244445</th>\n",
       "      <td>5</td>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       label\n",
       "0        1        deer\n",
       "111111   2    airplane\n",
       "222222   3  automobile\n",
       "233334   4        ship\n",
       "244445   5    airplane"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df_sort = y_df.sort_values(by=['id'], axis=0, ascending=True)\n",
    "y_df_sort.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f068837a-75ee-4f9c-80be-45d5b825590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df_sort.to_csv((data_dir / 'submission.csv').as_posix(), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec271aa-43e3-42a0-96bb-50ca695750b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
