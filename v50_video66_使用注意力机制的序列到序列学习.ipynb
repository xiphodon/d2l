{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f6a766d-a57f-4eec-a7e6-9d62eb24b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import utils\n",
    "import torchvision\n",
    "from torchvision.io import image\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import collections\n",
    "import re\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74e08a55-4bc3-480d-9cf3-86aa3608955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqEncoder(utils.Encoder):\n",
    "    \"\"\"用于序列到序列学习的循环神经网络编码器\"\"\"\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout=0, **kwargs):\n",
    "        super(Seq2SeqEncoder, self).__init__(**kwargs)\n",
    "        # 嵌入层\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers, dropout=dropout)\n",
    "        # self.rnn = nn.LSTM(embed_size, num_hiddens, num_layers, dropout=dropout)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        # 输出'X'的形状：(batch_size,num_steps,embed_size)\n",
    "        X = self.embedding(X)\n",
    "        # 在循环神经网络模型中，第一个轴对应于时间步\n",
    "        X = X.permute(1, 0, 2)\n",
    "        # 如果未提及状态，则默认为0\n",
    "        output, state = self.rnn(X)\n",
    "        # output的形状:(num_steps,batch_size,num_hiddens)\n",
    "        # state的形状:(num_layers,batch_size,num_hiddens)\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21b47d56-e062-4efa-95bd-5ff2a466e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoder(utils.Decoder):\n",
    "    \"\"\"带有注意力机制解码器的基本接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionDecoder, self).__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbbaea7f-1a3e-41b1-b9ed-e8fefba950e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqAttentionDecoder(AttentionDecoder):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, encoder, dropout=0, **kwargs):\n",
    "        super(Seq2SeqAttentionDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.attention = utils.AdditiveAttention(num_hiddens, num_hiddens, num_hiddens, dropout)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers, dropout=dropout)\n",
    "        # self.rnn = nn.LSTM(embed_size + num_hiddens, num_hiddens, num_layers, dropout=dropout)\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
    "        # outputs的形状为(batch_size，num_steps，num_hiddens).\n",
    "        # hidden_state的形状为(num_layers，batch_size，num_hiddens)\n",
    "        outputs, hidden_state = enc_outputs\n",
    "        # LSTM 的 state 包含 h和c\n",
    "        if isinstance(self.encoder.rnn, nn.LSTM) and isinstance(self.rnn, nn.GRU):\n",
    "            return (outputs.permute(1, 0, 2), hidden_state[0], enc_valid_lens)\n",
    "        elif isinstance(self.encoder.rnn, nn.GRU) and isinstance(self.rnn, nn.LSTM):\n",
    "            _c_n = torch.zeros_like(hidden_state)\n",
    "            return (outputs.permute(1, 0, 2), (hidden_state, _c_n), enc_valid_lens)\n",
    "        else:\n",
    "            return (outputs.permute(1, 0, 2), hidden_state, enc_valid_lens)\n",
    "            \n",
    "        \n",
    "    def forward(self, X, state):\n",
    "        # enc_outputs的形状为(batch_size,num_steps,num_hiddens).\n",
    "        # hidden_state的形状为(num_layers,batch_size, num_hiddens)\n",
    "        enc_outputs, hidden_state, enc_valid_lens = state\n",
    "        # 输出X的形状为(num_steps,batch_size,embed_size)\n",
    "        X = self.embedding(X).permute(1, 0, 2)\n",
    "        outputs, self._attention_weights = [], []\n",
    "        for x in X:\n",
    "            # x的形状为(batch_size,embed_size)\n",
    "            # query的形状为(batch_size,1,num_hiddens)\n",
    "            if isinstance(self.rnn, nn.GRU):\n",
    "                query = torch.unsqueeze(hidden_state[-1], dim=1)\n",
    "            else:\n",
    "                query = torch.unsqueeze(hidden_state[0][-1], dim=1)\n",
    "            # context的形状为(batch_size,1,num_hiddens)\n",
    "            context = self.attention(query, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "            # 在特征维度上连结,x: upsqueeze(dim=1)后，形状为(batch_size,1,embed_size)\n",
    "            # cat后形状为(batch_size,1,embed_size+num_hiddens)\n",
    "            x = torch.cat((context, torch.unsqueeze(x, dim=1)), dim=-1)\n",
    "            # 将x变形为(1,batch_size,embed_size+num_hiddens)\n",
    "            out, hidden_state = self.rnn(x.permute(1, 0, 2), hidden_state)\n",
    "            outputs.append(out)\n",
    "            self._attention_weights.append(self.attention.attention_weights)\n",
    "        # 全连接层变换后，outputs的形状为\n",
    "        # (num_steps,batch_size,vocab_size)\n",
    "        outputs = self.dense(torch.cat(outputs, dim=0))\n",
    "        return outputs.permute(1, 0, 2), [enc_outputs, hidden_state, enc_valid_lens]\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28afdc7a-a542-4a4f-b53c-041765396c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 7, 10]), 3, torch.Size([4, 7, 16]), 2, torch.Size([4, 16]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Seq2SeqEncoder(vocab_size=10, embed_size=8, num_hiddens=16, num_layers=2)\n",
    "encoder.eval()\n",
    "decoder = Seq2SeqAttentionDecoder(\n",
    "    vocab_size=10, embed_size=8, num_hiddens=16, num_layers=2, encoder=encoder)\n",
    "decoder.eval()\n",
    "X = torch.zeros((4, 7), dtype=torch.long)  # (batch_size,num_steps)\n",
    "state = decoder.init_state(encoder(X), None)\n",
    "output, state = decoder(X, state)\n",
    "output.shape, len(state), state[0].shape, len(state[1]), state[1][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3623688-0834-44c7-96b3-9e181f56fd2d",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8750ff19-b3ab-417b-a20a-40efe0444c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50/250, loss: 0.060\n",
      "epoch: 100/250, loss: 0.030\n",
      "epoch: 150/250, loss: 0.023\n",
      "epoch: 200/250, loss: 0.021\n",
      "epoch: 250/250, loss: 0.020\n",
      "loss 0.020, 5587.4 tokens/sec on cuda:0\n"
     ]
    }
   ],
   "source": [
    "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1\n",
    "batch_size, num_steps = 64, 10\n",
    "lr, num_epochs, device = 0.005, 250, utils.try_gpu()\n",
    "\n",
    "train_iter, src_vocab, tgt_vocab = utils.load_data_nmt(batch_size, num_steps)\n",
    "encoder = Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "decoder = Seq2SeqAttentionDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers, encoder, dropout)\n",
    "net = utils.EncoderDecoder(encoder, decoder)\n",
    "utils.train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e87c03f-561c-453b-b6b2-e86d64af2b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go . => va !, bleu 1.000\n",
      "i lost . => j'ai perdu ., bleu 1.000\n",
      "he's calm . => il est riche ., bleu 0.658\n",
      "i'm home . => je suis chez moi ., bleu 1.000\n"
     ]
    }
   ],
   "source": [
    "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
    "for eng, fra in zip(engs, fras):\n",
    "    translation, dec_attention_weight_seq = utils.predict_seq2seq(net, eng, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "    print(f'{eng} => {translation}, bleu {utils.bleu(translation, fra, k=2):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ee59739-2b1e-475d-b919-41c5a9afb0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights = torch.cat([step[0][0][0] for step in dec_attention_weight_seq], 0).reshape((1, 1, -1, num_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aec71a10-c0ea-454b-978e-bce1b4258488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 180x180 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 加上一个包含序列结束词元\n",
    "utils.show_heatmaps(attention_weights[:, :, :, :len(engs[-1].split()) + 1].cpu(), xlabel='Key positions', ylabel='Query positions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba662204-e05a-4635-927f-c7e79b51ebfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
