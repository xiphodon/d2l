{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca2cc82a-e3fb-4701-b8b2-05440235e0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import utils\n",
    "import torchvision\n",
    "from torchvision.io import image\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "927c3ad8-ea57-4315-a3e0-59c62c1ab929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_conv(X, K):\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] + h - 1, X.shape[1] + w - 1))\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            Y[i: i + h, j: j + w] += X[i, j] * K\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44041011-bb31-4168-8073-0ad897ff712a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  1.],\n",
       "        [ 0.,  4.,  6.],\n",
       "        [ 4., 12.,  9.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "trans_conv(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e05e5f86-cf08-4d8f-a84e-25313271d4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  0.,  1.],\n",
       "          [ 0.,  4.,  6.],\n",
       "          [ 4., 12.,  9.]]]], grad_fn=<SlowConvTranspose2DBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, K = X.reshape(1, 1, 2, 2), K.reshape(1, 1, 2, 2)\n",
    "tconv = nn.ConvTranspose2d(1, 1, kernel_size=2, bias=False)\n",
    "tconv.weight.data = K\n",
    "tconv(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b18c38c-739b-4646-ac66-913a2c2f3855",
   "metadata": {},
   "source": [
    "# 填充、步幅和多通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63383d6f-0e50-424b-9d95-afcb7a9577e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[4.]]]], grad_fn=<SlowConvTranspose2DBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 填充作用于输出，padding=1，输出去除padding后显示\n",
    "tconv = nn.ConvTranspose2d(1, 1, kernel_size=2, padding=1, bias=False)\n",
    "tconv.weight.data = K\n",
    "tconv(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed14a093-7927-4a76-9e32-fa0a8d15b2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 1.],\n",
       "          [0., 0., 2., 3.],\n",
       "          [0., 2., 0., 3.],\n",
       "          [4., 6., 6., 9.]]]], grad_fn=<SlowConvTranspose2DBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 步幅为2\n",
    "tconv = nn.ConvTranspose2d(1, 1, kernel_size=2, stride=2, bias=False)\n",
    "tconv.weight.data = K\n",
    "tconv(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beea6b3c-699e-430b-a390-698cb29a08a8",
   "metadata": {},
   "source": [
    "# 输出尺寸：\n",
    "# y_w = s * (x_w - 1) + k_w - 2 * p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fd2dc0c-95ab-4daf-ae9c-c413e17018b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(size=(1, 10, 16, 16))\n",
    "conv = nn.Conv2d(10, 20, kernel_size=5, padding=2, stride=3)\n",
    "tconv = nn.ConvTranspose2d(20, 10, kernel_size=5, padding=2, stride=3)\n",
    "tconv(conv(X)).shape == X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8391e77c-f404-4f5a-9338-8f193250375b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
