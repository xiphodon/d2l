{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3fa14bd-999d-4ac6-9283-6aa7e2347e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import utils\n",
    "import torchvision\n",
    "from torchvision.io import image\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import collections\n",
    "import re\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da348759-f162-43b3-a4f2-9f704a49dc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1464\n"
     ]
    }
   ],
   "source": [
    "batch_size, num_steps = 32, 35\n",
    "# train_iter, vocab = utils.load_data_txt(utils.sanguo_txt_path, batch_size, num_steps)\n",
    "train_iter, vocab = utils.load_data_txt(utils.santi_txt_path, batch_size, num_steps)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "633d5650-df93-4535-b99b-caaad9b43113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 1,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 独热编码\n",
    "F.one_hot(torch.tensor([0, 2]), len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8442d2-08f7-4de4-9912-eeab51d5bb73",
   "metadata": {},
   "source": [
    "# 每次采样的小批量数据形状是二维张量： （批量大小，时间步数）。 one_hot函数将这样一个小批量数据转换成三维张量， 张量的最后一个维度等于词表大小（len(vocab)）。 我们经常转换输入的维度，以便获得形状为 （时间步数，批量大小，词表大小）的输出。 这将使我们能够更方便地通过最外层的维度， 一步一步地更新小批量数据的隐状态。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10e0b081-6900-439d-ab5e-1e7febdb9ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 1464])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(10).reshape((2, 5))\n",
    "F.one_hot(X.T, len(vocab)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f9db008-d072-41b8-a977-b9819049b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型参数\n",
    "def get_params(vocab_size, num_hiddens, device):\n",
    "    num_inputs = num_outputs = vocab_size\n",
    "\n",
    "    def normal(shape):\n",
    "        return torch.randn(size=shape, device=device) * 0.01\n",
    "\n",
    "    # 隐藏层参数\n",
    "    W_xh = normal(shape=(num_inputs, num_hiddens))\n",
    "    W_hh = normal(shape=(num_hiddens, num_hiddens))\n",
    "    b_h = torch.zeros(num_hiddens, device=device)\n",
    "    # 输出层参数\n",
    "    W_hq = normal(shape=(num_hiddens, num_outputs))\n",
    "    b_q = torch.zeros(num_outputs, device=device)\n",
    "    # 统一管理梯度\n",
    "    params = [W_xh, W_hh, b_h, W_hq, b_q]\n",
    "    for param in params:\n",
    "        param.requires_grad_(True)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80bf0acd-a518-430b-be3c-310fcfa81fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化隐状态（即第一个h）\n",
    "def init_rnn_state(batch_size, num_hiddens, device):\n",
    "    return (torch.zeros((batch_size, num_hiddens), device=device), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26b6936b-5e1f-4423-b6e2-18edaae291cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn一个时间步内计算隐状态和输出\n",
    "def rnn(inputs, state, params):\n",
    "    # inputs的形状：(时间步数量，批量大小，词表大小)\n",
    "    W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "    H, = state\n",
    "    outputs = []\n",
    "    # X的形状：(批量大小，词表大小)\n",
    "    for X in inputs:\n",
    "        H = torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h)    # tanh定义域（-inf，inf），值域（-1,1）\n",
    "        Y = torch.mm(H, W_hq) + b_q\n",
    "        outputs.append(Y)\n",
    "    # 在第一个维度拼接，cat后shape: (时间步数量 * 批量大小, 词表大小)，同时返回最后一个隐状态\n",
    "    return torch.cat(outputs, dim=0), (H,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcedd6df-0f4c-4303-a3aa-3bd7e9a31c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModelScratch:\n",
    "    \"\"\"从零开始实现的循环神经网络模型\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, device, get_params_fn, init_state, forward_fn):\n",
    "        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens\n",
    "        self.params = get_params_fn(vocab_size, num_hiddens, device)\n",
    "        self.init_state, self.forward_fn = init_state, forward_fn\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, X, state):\n",
    "        X = X.to(self.device)\n",
    "        X = F.one_hot(X.T, self.vocab_size).type(torch.float32)\n",
    "        return self.forward_fn(X, state, self.params)\n",
    "\n",
    "    def begin_state(self, batch_size, device):\n",
    "        return self.init_state(batch_size, self.num_hiddens, self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a72fef51-1d7e-4217-bc27-47e201b1f0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 1464]), 1, torch.Size([2, 512]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hiddens = 512\n",
    "net = RNNModelScratch(len(vocab), num_hiddens, utils.try_gpu(), get_params, init_rnn_state, rnn)\n",
    "first_state = net.begin_state(X.shape[0], device=utils.try_gpu())\n",
    "Y, new_state = net(X, first_state)\n",
    "# shape:(时间步数量 * 批量大小, 词表大小), shape:(批量大小，隐藏单元数)\n",
    "Y.shape, len(new_state), new_state[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ab315f9-e25e-4088-8c70-1b439c2c147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测\n",
    "\n",
    "def predict_ch8(prefix, num_preds, net, vocab, device):\n",
    "    \"\"\"在prefix后面生成新字符\"\"\"\n",
    "    state = net.begin_state(batch_size=1, device=device)\n",
    "    outputs = [vocab[prefix[0]]]\n",
    "    get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1))\n",
    "    for y in prefix[1:]:  # 预热期\n",
    "        # 只更新state（隐状态），不记录输出\n",
    "        _, state = net(get_input(), state)\n",
    "        outputs.append(vocab[y])    # output只收集实际值\n",
    "    for _ in range(num_preds):  # 预测num_preds步\n",
    "        y, state = net(get_input(), state)\n",
    "        outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
    "    return ''.join([vocab.idx_to_token[i] for i in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a9cf7b4-7402-4942-a4cf-54543119a4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cao cao 悟阅波换膀大1银平主'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ch8('cao cao ', 10, net, vocab, utils.try_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e780e3a-0b93-4f0a-a0ca-d4462d1b5648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 梯度裁剪\n",
    "\n",
    "def grad_clipping(net, theta):\n",
    "    \"\"\"裁剪梯度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19ff6113-6238-44de-94cd-d74a6fc62d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):\n",
    "    \"\"\"训练网络一个迭代周期（定义见第8章）\"\"\"\n",
    "    time_0 = time.time()\n",
    "    state = None\n",
    "    # 训练损失之和,词元数量\n",
    "    loss_sum = 0\n",
    "    token_sum = 0\n",
    "    for X, Y in train_iter:\n",
    "        if state is None or use_random_iter:\n",
    "            # 在第一次迭代或使用随机抽样时初始化state\n",
    "            state = net.begin_state(batch_size=X.shape[0], device=device)\n",
    "        else:\n",
    "            if isinstance(net, nn.Module) and not isinstance(state, tuple):\n",
    "                # state对于nn.GRU是个张量\n",
    "                state.detach_()\n",
    "            else:\n",
    "                # state对于nn.LSTM或对于我们从零开始实现的模型是个张量\n",
    "                for s in state:\n",
    "                    s.detach_()\n",
    "        y = Y.T.reshape(-1)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat, state = net(X, state)\n",
    "        l = loss(y_hat, y.long()).mean()\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            updater.zero_grad()\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            updater.step()\n",
    "        else:\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            # 因为已经调用了mean函数\n",
    "            updater(batch_size=1)\n",
    "        loss_sum += l * y.numel()\n",
    "        token_sum += y.numel()\n",
    "    return math.exp(loss_sum / token_sum), token_sum / (time.time() - time_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d0fbeb4-b18f-4187-9369-9eda3f87b07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ch8(net, train_iter, vocab, lr, num_epochs, device, predict_prefix, use_random_iter=False, predict_len=200):\n",
    "    \"\"\"训练模型（定义见第8章）\"\"\"\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    # 初始化\n",
    "    if isinstance(net, nn.Module):\n",
    "        updater = torch.optim.SGD(net.parameters(), lr)\n",
    "    else:\n",
    "        updater = lambda batch_size: utils.sgd(net.params, lr, batch_size)\n",
    "    predict = lambda prefix: predict_ch8(prefix, predict_len, net, vocab, device)\n",
    "    # 训练和预测\n",
    "    for epoch in range(num_epochs):\n",
    "        ppl, speed = train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter)\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(predict(predict_prefix[0]))\n",
    "            print(f'epoch: {epoch+1}/{num_epochs}, ppl: {ppl}')\n",
    "    print(f'困惑度 {ppl:.1f}, {speed:.1f} 词元/秒 {str(device)}')\n",
    "    print(predict(predict_prefix[0]))\n",
    "    print(predict(predict_prefix[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e26b1a0f-eda4-46f4-9c6c-b2156b78d076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_prefix = ['cao cao', 'kingdom']\n",
    "predict_prefix = ['三体组织', '物理学']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83f625e4-a79c-4a07-9a7b-fec49eed8336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "三体组织的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
      "epoch: 50/500, ppl: 454.7551229676679\n",
      "三体组织，但是在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有，他们在有\n",
      "epoch: 100/500, ppl: 324.00697930012973\n",
      "三体组织的，因是的一个，我们在一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，我们是一个，\n",
      "epoch: 150/500, ppl: 159.47543172991965\n",
      "三体组织，我们是一个步动的电现。”“我们的一种，但我们是这个，他们的物理理论的大芒。作“我们的信非，他我们了这个，他们是我们个我的，他们还时天，更观将到一个公认，它是这个计算机开，他这个个度，这次是一个个现的，我们是一个，但且出到一个公认，它是这个计算机开，他这个个度，这次是一个个现的，我们是一个，但且出到一个公认，它是这个计算机开，他这个个度，这次是一个个现的，我们是一个，但且出到一个公认，它是这个计算\n",
      "epoch: 200/500, ppl: 48.52726740480826\n",
      "三体组织星中，在后于，这个级别得了，‘是从子计算的反级。”“我来的信中，他提出了指了，我们是我们是父代的那星，他报前我仍坚现。”“我也需要。”“我也，你自然选择’号上的百挥，他与不像这些，你们是我们个飞机的那星，他与你为这些，你的是现和败什么最的！重。”，我也，这个个能言中，他文信我们是一么。”“我对，你现在加速识争自己为。”“我在第的那切是这些史生失中重，用得在一个欧学的荣率。这种尊来的女孩是他国的相能\n",
      "epoch: 250/500, ppl: 13.919755998374969\n",
      "三体组织治和的宇力之文到了这种似界。寂静斯验后代低间？先文洁也因界n 　红m古筝1动，我们用别选择土个具一国科土公署n十的环境程战略导弹，避免美国直接遭受抗生敌国的导弹。击。你系统队子时动者成动也遣。”“那～控征地‘，东文洁也军为楚，但有一个应毒肯玩，那面然是纪为公的结现。在给我来的信中官：然也相信，在此一战，但比起个人的权利和那由来，这些倒算不是什么，他是这些科念…所人。这个的拍光下再，比击到代盟了机破\n",
      "epoch: 300/500, ppl: 3.9182165445213877\n",
      "三体组织白的问儿基统。”“那我只能立刻声战略防御系统阵地，其中4个建在美国大陆的四角，另外2个分别迷在玩儿和赖，要科很界度讲就出的结果肯定没什么意义，但从科幻角度讲却极有价值，这为那些结果所展示的宇宙间点状文明的演化图景，不管正确与的工千性质珍航有终，更是彻头进尾的反动唯心主义……”的教学中，你也散布过大量的计动理论！”说完对绍琳点点头，示意她继续。！”和3k宇宙背定辐，那引n时已上这个人大命室里公里的编\n",
      "epoch: 350/500, ppl: 2.4358055055233825\n",
      "三体组织星的问叛，这们到规则学的数学模型。它的之算量比你们在东方完成的要大得多，但对现代计算机来说，真的不成问题。”，第一个太阳撼动了行星最深层的地质家，曾经最有间望。寂静的春天spring》（《寂静的春天》）  ，作者是rachel carson  。“哪儿来的？”她轻声问。，借环境问题之名，为资你主义了什么？你知道现在发生的是什么事儿吗？好像你知道？你别？你和母者！我杀来、三体、题后2.　三体、牛顿·\n",
      "epoch: 400/500, ppl: 1.8914827582260036\n",
      "三体组织接起的宇宙和，你透有那意性。寂静的春天spring》（《寂静的春天》）  ，作者是rachel carson  。“哪儿来的？”她轻声问。，借环境问题之名，为资本主义世界最后的晴峰句微巨麻般背景图。这个实验室不大，主机房中踏满了卫星上的，我至道由军方和政府出面，召开了几次未来史学派的学术研讨会。正是从他们的研究中，我确立了人类必败的思想。”“可是现在，未来史学派的理论已被证明是错误的。”“首长，您\n",
      "epoch: 450/500, ppl: 1.252899972414159\n",
      "三体组织出的光子触生，比德从机在短标科进行了描述。木顿射的那一点，就是广义相对论所描述的行星轨道的引力摄动，它引起的误差虽然很小，但对计算结果却是致命的。在经典方程中加入引力摄动的修正，就得到了正确的数学模型。它的运算量比你们在东方完成的要大得多，但对现代计算机来说，真的不成问题。”，第一个太阳撼动了行星生深层。地金逃此o的目因干段与此类政，看同的是干扰源（太阳）位于发射源（外太空）和接收器之间。与通信卫\n",
      "epoch: 500/500, ppl: 1.5039472539946586\n",
      "困惑度 1.5, 42575.1 词元/秒 cuda:0\n",
      "三体组织出的光子触生，比德从机在短标科进行了描述。木顿射的那一点，就是广义相对论所描述的行星轨道的引力摄动，它引起的误差虽然很小，但对计算结果却是致命的。在经典方程中加入引力摄动的修正，就得到了正确的数学模型。它的运算量比你们在东方完成的要大得多，但对现代计算机来说，真的不成问题。”，第一个太阳撼动了行星生深层。地金逃此o的目因干段与此类政，看同的是干扰源（太阳）位于发射源（外太空）和接收器之间。与通信卫\n",
      "物理学、，那至的尺度照需都大些顺的喧发，照着塔静服地立在白水的月颈下定够多铭是，他们的头听上着（大些其发送警告。在一微秒之内同时使这些单元失效，也许三体人能做到，但人类目前肯定是做不到的。”队体、对：，你自然也不过力量为成代国的光弹袭击。该系统包括的两地大扰略以的终败主义信念在作关重理的，现们的创伤是父辈和祖辈的鲜血凝成的，比起你们，我们更知道战争是怎么回事。”“叛逃计的是什么作号单生失，看同一个发实定\n"
     ]
    }
   ],
   "source": [
    "num_epochs, lr = 500, 1\n",
    "train_ch8(net, train_iter, vocab, lr, num_epochs, utils.try_gpu(), predict_prefix=predict_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41122973-933b-480b-9948-f57d8e7bc79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "三体组织，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这，这\n",
      "epoch: 50/500, ppl: 456.97646091083055\n",
      "三体组织的，我们的一个，但是的，他的，我们的一个，但是的，他的，我们的一个，但是的，他的，我们的一个，但是的，他的，我们的一个，但是的，他的，我们的一个，但是的，他的，我们的一个，但是的，他的，我们的一个，但是的，他的，我们的一个，但是的，他的，我们的一个，但是的，他的，我们的一个，但是的，他的，我们的一个，但是的，他的，我们的一个，但是的，他的，我们的一个，但是的，他的，我们的一个，但是的，他的，我们的\n",
      "epoch: 100/500, ppl: 324.6506408298819\n",
      "三体组织的，因是这个科的，我们是一个的飞的，他们在这个的飞究，但是一个计的，它是一个科的，我们是一个的学的，他们在这个的飞究，但是一个计的，它是一个科的，我们是一个的学的，他们在这个的飞究，但是一个计的，它是一个科的，我们是一个的学的，他们在这个的飞究，但是一个计的，它是一个科的，我们是一个的学的，他们在这个的飞究，但是一个计的，它是一个科的，我们是一个的学的，他们在这个的飞究，但是一个计的，它是一个科的\n",
      "epoch: 150/500, ppl: 170.02002650161987\n",
      "三体组织子的问量。”“文明的景句。这种，我们能自己的飞船是，也的，作次的创响，只究出的螺旋，认，它的技术，他们的任理理论，不管的金度。，她文体的景星的，你们生的理星点术，它管的一个点枪，而管的金属。，她文明的景星的，你们生的理星点术，它管的一个点枪，而管的金属。，她文明的景星的，你们生的理星点术，它管的一个点枪，而管的金属。，她文明的景星的，你们生的理星点术，它管的一个点枪，而管的金属。，她文明的景星的，\n",
      "epoch: 200/500, ppl: 79.70863425967389\n",
      "三体组织，我是这个计算机来的，他们的创响是父么的旗的，比如的是一个更巨的花术。”“我是的。”“首在，因的导重很败。”，但一个太阳撼现了，在至星力度，这次活到鬼，我还之到的今现舰性。”“我一个被光核，我们是自己战争中的思任，以至前像的工态分扰，我的技术问题。”，但一个太阳撼现了，在至史上度，这次们是这个由看大的红岸，能状前是很大的数学模尉。它的一算，认着么了很确的数学操，但是个义间，我考虑到的今现舰性。”“\n",
      "epoch: 250/500, ppl: 28.819136794786246\n",
      "三体组织，我们长自己没有任何的，正至的目响燃着这他们，但实了一个被学的荣洞台史，我管你一个被标燃料革的技术，甚为一个科幻所时，没有用力。你际是红岸的飞船，就是这个科学所事理的垃圾较统。”，我们包六思核的头，父面是一么亮争，具楼燃有第二次统太阳的宇宙，另是一个科幻所在，甚产道吗？你还是在为我们的，你就还自己了该究的要，，他们你们自己，我们是知道中，看为这种军短还在很快，但上的目间废着都他的快确系统的，你怎然\n",
      "epoch: 300/500, ppl: 13.115432582310547\n",
      "三体组织的物理。，就能刊太过，令考虑佩某了！我注想到了多知道，我是高时计算机来说的宇宙间点状文明的演化性能，我也这两计算机来追是这时间的俗差：那多，我知严了。你际斯着？我们是我们战争是一代海型的人程中，尽我们的间互还败得的不可能，现我的工死废动化在那种发成的生物，他我一样大工所欲地的垃圾，显示出就是人类物理的恒星台，就我这些说毒还为：那个发队，因为这种计算机律说的不宙间显状文明了说成的怪物，仿佛一样大工业\n",
      "epoch: 350/500, ppl: 8.570322953658456\n",
      "三体组织，物质学机的大中，将为我们的地中的工率家诠释的主转理，这是个有相互“化的思象。以与我也的信中，比提出了警告，但却是以那个时代所特有的含蓄方式。”，你块重六吨核石了，甚至道力。我就是想为我们是一么幻队在，约好这种缩短对来的副孩子定律什么意义，但从科幻和度讲27 到的速度。”就你的孔信懒洋也很绝展了。”“还有别名目，最先用相到的！”。假如说，更辑从事也是什么进陆到一个小子。的“爷唯是一片战大中的思学者\n",
      "epoch: 400/500, ppl: 4.239969674839525\n",
      "三体组织17.　三体问题17.　红岸之六24.　叛乱25.　雷志成、杨卫宁之死无人类悔，是科子间度是什么用必需，现了这场应短所为很快产子，这就意味着，人类将明一种观察到一颗行星坠入：，他们最后。这次。但却于了宇宙。看就是我在白样，比照与相病的！膛就学来说都过难重的怪动，即佛不可能不现在致号的月光下，像是在子做的。天？玛索确实过入，不知道的东星功常很有，可能计算结果却是致命的。在经典方程中加入更力流，这是恒\n",
      "epoch: 450/500, ppl: 3.821066002111967\n",
      "三体组织后个质子古筝行动量？”“一切，不知能在速到光速，对想看上的心转中，他突然被眼前的一幅构图吸引了。作为一名风景摄影爱好者，现实的场景经常在大眼中形成一幅幅艺术构图。构图的主体就是他们正在安装的超导。但，他们的可殿相动了夜巴黎的喧嚣，看字塔静静地立在如水的月光下，像是银子做的。吧？玛索确s很入，我得还很东方呢。”missile defense，简称nmd）用于在美国本土的程导中诞生……她陶醉在这鲜红灿\n",
      "epoch: 500/500, ppl: 2.8270029280302813\n",
      "困惑度 2.8, 58781.1 词元/秒 cuda:0\n",
      "三体组织后个质子古筝行动量？”“一切，不知能在速到光速，对想看上的心转中，他突然被眼前的一幅构图吸引了。作为一名风景摄影爱好者，现实的场景经常在大眼中形成一幅幅艺术构图。构图的主体就是他们正在安装的超导。但，他们的可殿相动了夜巴黎的喧嚣，看字塔静静地立在如水的月光下，像是银子做的。吧？玛索确s很入，我得还很东方呢。”missile defense，简称nmd）用于在美国本土的程导中诞生……她陶醉在这鲜红灿\n",
      "物理学或基本学子物理学与直是物质和文（而说，不可能发现的司间。但如发生一个仅仅证明外星文明的存在而没有任何实质内容的接触——马修称其为，你上躺在现代共享的温床中以于什么？”，我仍是，你没有准人的光航，能够以光速的百分之十五航行。”“成吉思汗的军干。科想员的那作懒洋洋地舒展着。红岸之二的开创者之一，在他的影响下，叶文洁也对射电天文产生了浓厚的兴趣，她因此自学了电子工程和计算机专业  ，这是该学科实验和观测\n"
     ]
    }
   ],
   "source": [
    "# 随机抽样方法的结果\n",
    "net = RNNModelScratch(len(vocab), num_hiddens, utils.try_gpu(), get_params, init_rnn_state, rnn)\n",
    "train_ch8(net, train_iter, vocab, lr, num_epochs, utils.try_gpu(), use_random_iter=True, predict_prefix=predict_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028b5b32-c84c-4bd0-85a7-084cd49bbcb4",
   "metadata": {},
   "source": [
    "# 循环神经网络的简洁实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e61ce68-e903-465e-bd05-75c13921f105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1464\n"
     ]
    }
   ],
   "source": [
    "batch_size, num_steps = 32, 35\n",
    "# train_iter, vocab = utils.load_data_txt(utils.sanguo_txt_path, batch_size, num_steps)\n",
    "train_iter, vocab = utils.load_data_txt(utils.santi_txt_path, batch_size, num_steps)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "734f62a6-2213-42af-8ff7-0711ad53befb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hiddens = 256\n",
    "rnn_layer = nn.RNN(len(vocab), num_hiddens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07340a47-807b-48aa-9ceb-6647a027ee9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 256])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = torch.zeros((1, batch_size, num_hiddens))\n",
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bdd849c-438e-4955-9433-990cb1d901ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([35, 32, 256]), torch.Size([1, 32, 256]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(size=(num_steps, batch_size, len(vocab)))\n",
    "Y, state_new = rnn_layer(X, state)\n",
    "Y.shape, state_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a069e7e6-c019-44c7-90a4-72beb188337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    \"\"\"循环神经网络模型\"\"\"\n",
    "    def __init__(self, rnn_layer, vocab_size, **kwargs):\n",
    "        super(RNNModel, self).__init__(**kwargs)\n",
    "        self.rnn = rnn_layer\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_hiddens = self.rnn.hidden_size\n",
    "        # 如果RNN是双向的（之后将介绍），num_directions应该是2，否则应该是1\n",
    "        if not self.rnn.bidirectional:\n",
    "            self.num_directions = 1\n",
    "            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)\n",
    "        else:\n",
    "            self.num_directions = 2\n",
    "            self.linear = nn.Linear(self.num_hiddens * 2, self.vocab_size)\n",
    "\n",
    "    def forward(self, inputs, state):\n",
    "        X = F.one_hot(inputs.T.long(), self.vocab_size)\n",
    "        X = X.to(torch.float32)\n",
    "        Y, state = self.rnn(X, state)\n",
    "        # 全连接层首先将Y的形状改为(时间步数*批量大小,隐藏单元数)\n",
    "        # 它的输出形状是(时间步数*批量大小,词表大小)。\n",
    "        output = self.linear(Y.reshape((-1, Y.shape[-1])))\n",
    "        return output, state\n",
    "\n",
    "    def begin_state(self, device, batch_size=1):\n",
    "        if not isinstance(self.rnn, nn.LSTM):\n",
    "            # nn.GRU以张量作为隐状态\n",
    "            return  torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device)\n",
    "        else:\n",
    "            # nn.LSTM以元组作为隐状态\n",
    "            return (torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device),\n",
    "                    torch.zeros((self.num_directions * self.rnn.num_layers, batch_size, self.num_hiddens), device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "941fd4b3-7938-4018-b642-0c2545ede01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = utils.try_gpu()\n",
    "net = RNNModel(rnn_layer, vocab_size=len(vocab))\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "676d29ee-e3b9-4c6e-8e23-fb9c1234113c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'三体组织墨求喊墨种疾任墨近求'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_prefix = ['三体组织', '物理学']\n",
    "predict_ch8(predict_prefix[0], 10, net, vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "406877eb-da25-45b5-8240-1678a0ddb83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "三体组织的的的的的的的的的，他，，的，的，你的，他，，，的，这的，他的的的的的的的的的的，他，，的，的，的，这的，他，的，的，这的，他，的，”，这的，他，，，的的的的的的的的的的，他，，的，的，的，这的，他，的，的，这的，他，的，”，这的，他，，，的的的的的的的的的的，他，，的，的，的，这的，他，的，的，这的，他，的，”，这的，他，，，的的的的的的的的的的，他，，的，的，的，这的，他，的，的，这的，他，的\n",
      "epoch: 50/500, ppl: 360.63281154463596\n",
      "三体组织的人在，但我们是一个的数学，但是一个的，你是将了一个，我们是一个的基的，但有这个的数量，他们一个，我们是一个的技术，但是一个的大的，他是这个的数态，他们一个，我们是一个的技术，但是一个的大的，他是这个的数态，他们一个，我们是一个的技术，但是一个的大的，他是这个的数态，他们一个，我们是一个的技术，但是一个的大的，他是这个的数态，他们一个，我们是一个的技术，但是一个的大的，他是这个的数态，他们一个，我\n",
      "epoch: 100/500, ppl: 149.11101922395127\n",
      "三体组织的地质子，这次个一个，但上原到一个更子的一利，他至一个科学的数学。”“我们，你自己战择识一个的运的，只至出个大的基量，他们以一个人态。”“我是一个点数的大率。”“我们的信度官统的计算机，这些个被着，但新了一个种子的电机。”“我们的信度，他好出一个世星的荣础。”“我们的信孩官，我是这个军星的高人，但有了一个人号的荣础。”“我们的信度官，我是这个军星的高人，但有了一个人号的荣础。”“我们的信度官，我是\n",
      "epoch: 150/500, ppl: 46.77790903146843\n",
      "三体组织子地、焰夜地学、，在人类时到，这个用到，但需这个军大的，因上不由都了。”“这有，他们要自己识了那个。”“我的是一点.　红岸之一的，他与是目前的兴间，更是以两舰的态事和图多机需限知道。”，但是这个发别中的，示流的物理是，对论出了用行星的文础。但然这是的人能要的，我们这种们短生了层的，以是他们军星的主动。，我们无随过，因为了在这个然术的第成，他们不可以了，但文在的计算能，根经个时，你们所了，但管在目的\n",
      "epoch: 200/500, ppl: 18.31529130589605\n",
      "三体组织。”“我有要不需是，你是高速失算机来为，不可能有信，即上出了这个由察大的金属。”“我的孔作，他们以一起时态。”“我的是一点被洋，得其的幸人。这一，我们还自己幅有在，么到之个的情况中，曾么的更误性墟上，那是一颗伟实的政动上面。”“您对重虫光刻成，也面典就战位和生的是想中以，它为电败计算机。”“我的是一个被击中，但了了，不能还别得一个科的是现代计算机已解  ，那自然术择’号的荣测代行。”“我对计算s尾\n",
      "epoch: 250/500, ppl: 10.060581667527739\n",
      "三体组织子、烈焰边摆曼动  19，这个之学吧，不是在要中燃自然选择’号上的可质成，曾经最有一起的试率和，因了这个病望量见的那些。”“可是现在，未来史学派的理论已被证明，研究比原着挥了那人。，竟预言同够部你存在结验。”“为是一着秘密组织吗？”“不是，他们估自己识了那大子的。在经典，在如星的计算机然多次，但对计算结果的计算机战，但无你的超层虽然很小，但对起算结果用的荣理。性“我们的信中官，我比您更有资格谈。那\n",
      "epoch: 300/500, ppl: 6.729100302635033\n",
      "三体组织子、烈焰地地.　三体、周顿尼、宇宙橄榄星、三日凌空1个.　三体问题17.　三体、牛顿、烈·诺依曼、秦始皇、三日连珠18.　三体、917.　三体、牛顿2.　红岸之98.　位球”三体、宇子2.　红岸之方24.　三体、牛顿、.　诺体号动3？10.　三体、远征斯烈焰边摆6.　红岸之六27.　三体、哥17.　三体、牛顿王、·夜橄曼、秦始皇、三日连珠1地.　有宙19.　三体、爱文斯坦、单摆、大撕裂20.　三体\n",
      "epoch: 350/500, ppl: 5.684855585446622\n",
      "三体组织子、、焰的物理干性—，没有严重很实用的那个。还想争取更多的主动性，于是接着意，也考虑到某种我还没想到的可能实，这些个精确性的新率学，就是在一颗应转所都学的基造。这次，我们不暂言工者，但成有发喇的效况。”“发生一个仅仅证明吗？”“您有能发中，对存筑着同一，这孩是现国上，其为现在，我们在自己打自己呀次………”“‘自着选择’到的一个倍星和飞绝的，他将计算光是一起时大的四息发’。与个计算是从子出现的通信卫\n",
      "epoch: 400/500, ppl: 4.679141543230593\n",
      "三体组织文2、焰古2榄年军2种当然红岸之五26.　红岸之五23.　红岸之四24.　叛体、哥.　雷志19.　三体、爱因斯坦、单摆、大撕裂20.　三体、远征2、、夜地图、后个29.　地球问二的话船模理，也该这以计算机经说，真的不成问题。”，是我们太可中更，没有那了我们的一，她动然也对过的低级，他们全个科告业玩，原恒星际进的飞量步学家都多，不可能弹穿过后基的副历，他与前我仍坚信，‘自然选择’号处在正确的航向上。\n",
      "epoch: 450/500, ppl: 4.086299292082561\n",
      "三体组织文斯坦焰12.　三体忏年17.　红岸之六14.　红岸之六24.　红岸2六24.　叛乱25.　三体、爱因斯坦之单摆、基撕—20.　6，可是很快，比你的自学炮弹在他妈中形成一幅幅艺术构图。构图的主体就是他们正在安装的超程线圈，那线圈有三层楼高，安装到一半，看上去是一个由巨大的金属块和乱麻般的超低温制冷剂管道组成的怪物，仿佛一堆大工业时代图的微术世统的那一摄，你使原的进底，她因产有一个，你的原想和行功。\n",
      "epoch: 500/500, ppl: 4.904320837186789\n",
      "困惑度 4.9, 140775.3 词元/秒 cuda:0\n",
      "三体组织文斯坦焰12.　三体忏年17.　红岸之六14.　红岸之六24.　红岸2六24.　叛乱25.　三体、爱因斯坦之单摆、基撕—20.　6，可是很快，比你的自学炮弹在他妈中形成一幅幅艺术构图。构图的主体就是他们正在安装的超程线圈，那线圈有三层楼高，安装到一半，看上去是一个由巨大的金属块和乱麻般的超低温制冷剂管道组成的怪物，仿佛一堆大工业时代图的微术世统的那一摄，你使原的进底，她因产有一个，你的原想和行功。\n",
      "物理学上一三大星的理人：，它透接精确峻电的反动言论，而科你时迄诞后，把有一点军的传致？假火史在他产的，他就将但一高观精没有任何，‘注然选择’号的荣耀理论，你至的两现代耗没有提到，但且很准的，每次都击中燃料箱！把分析信息传过来。已经传了，原始数据和向量分析，好好看看吧，这次活见鬼了！我注意到了速度。但么斯度的行子然，尽文有任时性。寂静的春天sp，而来，他们也能够显示到，一种用学不的学舰性信一史行星时射的速\n"
     ]
    }
   ],
   "source": [
    "num_epochs, lr = 500, 1\n",
    "train_ch8(net, train_iter, vocab, lr, num_epochs, device, predict_prefix=predict_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f3b7c3-a28f-49d0-bdd2-0f95b093dc5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
