{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2af9ea4e-738b-4b9b-8ecb-a5ac25cef15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import utils\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8d6fdf-8be9-4482-9df2-83d83e80f5cb",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/competitions/classify-leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c45f5d52-d4cb-46e9-a078-f552ac110d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(r'../data/classify-leaves')\n",
    "data_csv_train = data_dir / 'train.csv'\n",
    "data_csv_test = data_dir / 'test.csv'\n",
    "data_images = data_dir / 'images'\n",
    "resnet34_state_dict_path = Path('../data/leaves_resnet34_state_dict.sd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a31a3532-4319-439b-890d-60f0bb31cf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeavesDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "        树叶数据集\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir: Path, data_csv: Path, transforms=None, is_train=True):\n",
    "        \"\"\"\n",
    "            data_dir: 数据集目录\n",
    "            data_csv: 数据-类对应文件\n",
    "            transforms：数据增广\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.data_csv = data_csv\n",
    "        self.class_mapping_path = data_dir / 'class_mapping.json'\n",
    "        self.transforms = transforms\n",
    "        self.is_train = is_train\n",
    "        self.class_mapping_dict = dict()\n",
    "        self.data_list = self.read_data()\n",
    "        \n",
    "    def read_data(self):\n",
    "        \"\"\"\n",
    "            读取数据\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(self.data_csv.as_posix())\n",
    "        if not self.class_mapping_path.exists():\n",
    "            unique_labels = df['label'].unique() \n",
    "            for i, class_name in enumerate(unique_labels):\n",
    "                self.class_mapping_dict[str(i)] = class_name\n",
    "                self.class_mapping_dict[class_name] = i\n",
    "            with open(self.class_mapping_path.as_posix(), 'w', encoding='utf8') as fp:\n",
    "                json.dump(self.class_mapping_dict, fp)\n",
    "        else:\n",
    "            with open(self.class_mapping_path.as_posix(), 'r', encoding='utf8') as fp:\n",
    "                self.class_mapping_dict = json.load(fp)\n",
    "        return df.values.tolist()\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # print(self.data_list[i])\n",
    "        if self.is_train:\n",
    "            _img_path, label = self.data_list[i]\n",
    "        else:\n",
    "            _img_path = self.data_list[i]\n",
    "            if isinstance(_img_path, list):\n",
    "                _img_path = _img_path[0]\n",
    "        img_path = self.data_dir / _img_path\n",
    "        img = Image.open(img_path.as_posix()).convert('RGB')\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "        return (img, self.class_mapping_dict[label]) if self.is_train else img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "163b2844-23be-4fd2-9652-52a07b34957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用RGB通道的均值和标准差，以标准化每个通道\n",
    "normalize = torchvision.transforms.Normalize(\n",
    "    [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "train_augs = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop(size=(112, 112), scale=(0.9, 1), ratio=(0.8, 1.2)),\n",
    "    torchvision.transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    normalize])\n",
    "\n",
    "test_augs = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(size=(112, 112)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc8d60a-a9fe-411c-967a-53f6fc4442be",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaves_dataset_train = LeavesDataset(data_dir, data_csv_train, transforms=train_augs)\n",
    "leaves_dataset_test = LeavesDataset(data_dir, data_csv_test, transforms=test_augs, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ca57890-ac06-4a78-a55d-b99b176979ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = torchvision.models.resnet34(pretrained=True)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0ca21f1-2694-4a68-8311-f8a21dcf4a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f91fcf37-bbbf-4c0e-8498-21682ef5a502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (relu2): ReLU(inplace=True)\n",
       "  (fc2): Linear(in_features=512, out_features=176, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自定义fc层，将最终的输出类别设置为当前需要的176\n",
    "net.fc = nn.Linear(net.fc.in_features, 512)\n",
    "net.add_module('relu2', nn.ReLU(inplace=True))\n",
    "net.add_module('fc2', nn.Linear(512, 176))\n",
    "nn.init.xavier_uniform_(net.fc.weight);\n",
    "nn.init.xavier_uniform_(net.fc2.weight);\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed4a3f93-fb21-4fba-8744-4a24c57fae45",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset_len = int(len(leaves_dataset_train) / 10)\n",
    "train_dataset_len = len(leaves_dataset_train) - valid_dataset_len\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(\n",
    "    dataset=leaves_dataset_train,\n",
    "    lengths=[train_dataset_len, valid_dataset_len],\n",
    "    generator=torch.Generator().manual_seed(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dab02605-c6e7-4dce-a02c-db630e0d78b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果param_group=True，输出层中的模型参数将使用十倍的学习率\n",
    "def train_fine_tuning(net, learning_rate, batch_size=128, num_epochs=5, weight_decay=1e-3, \n",
    "                      fc_lr_times=20, param_group=True, freeze=False, train_all_data=False):\n",
    "    devices = utils.try_all_gpus()\n",
    "    loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "    if freeze:\n",
    "        for name, param in net.named_parameters():\n",
    "            if name not in [\"fc.weight\", \"fc.bias\", \"fc2.weight\", \"fc2.bias\"]:\n",
    "                param.requires_grad = False\n",
    "    if param_group:\n",
    "        params_1x = [param for name, param in net.named_parameters()\n",
    "             if name not in [\"fc.weight\", \"fc.bias\", \"fc2.weight\", \"fc2.bias\"]]\n",
    "        trainer = torch.optim.SGD(\n",
    "            [\n",
    "                {'params': params_1x}, \n",
    "                {'params': net.fc.parameters(), \n",
    "                 'lr': learning_rate * fc_lr_times}\n",
    "            ], \n",
    "            lr=learning_rate, \n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "    else:\n",
    "        trainer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    if train_all_data:\n",
    "        train_iter = torch.utils.data.DataLoader(\n",
    "            leaves_dataset_train, batch_size=batch_size, shuffle=True)\n",
    "        valid_iter = None\n",
    "    else:\n",
    "        train_iter = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        valid_iter = torch.utils.data.DataLoader(\n",
    "            valid_dataset, batch_size=batch_size)\n",
    "    utils.train_gpus(net, train_iter, valid_iter, loss, trainer, num_epochs, devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83a317c3-3408-41ab-abe2-380f35fe79fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1/5 ---\n",
      "training on: [device(type='cuda', index=0)], [2024-06-13 08:51:29]\n",
      "epoch: 1/6, loss 3.525, train acc 0.284, test acc 0.488\n",
      "epoch: 2/6, loss 1.500, train acc 0.615, test acc 0.647\n",
      "epoch: 3/6, loss 0.986, train acc 0.736, test acc 0.731\n",
      "epoch: 4/6, loss 0.737, train acc 0.803, test acc 0.761\n",
      "epoch: 5/6, loss 0.584, train acc 0.842, test acc 0.796\n",
      "epoch: 6/6, loss 0.470, train acc 0.872, test acc 0.809\n",
      "*** 434.2 examples/sec on [device(type='cuda', index=0)] - [0:00:03:48], all: [0:00:10:05] ***\n",
      "--- 2/5 ---\n",
      "training on: [device(type='cuda', index=0)], [2024-06-13 09:01:33]\n",
      "epoch: 1/6, loss 0.388, train acc 0.894, test acc 0.823\n",
      "epoch: 2/6, loss 0.332, train acc 0.908, test acc 0.819\n",
      "epoch: 3/6, loss 0.289, train acc 0.922, test acc 0.837\n",
      "epoch: 4/6, loss 0.252, train acc 0.933, test acc 0.858\n",
      "epoch: 5/6, loss 0.217, train acc 0.942, test acc 0.861\n",
      "epoch: 6/6, loss 0.199, train acc 0.947, test acc 0.866\n",
      "*** 434.9 examples/sec on [device(type='cuda', index=0)] - [0:00:03:47], all: [0:00:08:29] ***\n",
      "--- 3/5 ---\n",
      "training on: [device(type='cuda', index=0)], [2024-06-13 09:10:03]\n",
      "epoch: 1/6, loss 0.171, train acc 0.954, test acc 0.863\n",
      "epoch: 2/6, loss 0.156, train acc 0.960, test acc 0.881\n",
      "epoch: 3/6, loss 0.144, train acc 0.961, test acc 0.885\n",
      "epoch: 4/6, loss 0.133, train acc 0.966, test acc 0.887\n",
      "epoch: 5/6, loss 0.119, train acc 0.970, test acc 0.894\n",
      "epoch: 6/6, loss 0.109, train acc 0.973, test acc 0.889\n",
      "*** 439.4 examples/sec on [device(type='cuda', index=0)] - [0:00:03:45], all: [0:00:08:24] ***\n",
      "--- 4/5 ---\n",
      "training on: [device(type='cuda', index=0)], [2024-06-13 09:18:28]\n",
      "epoch: 1/6, loss 0.107, train acc 0.971, test acc 0.884\n",
      "epoch: 2/6, loss 0.096, train acc 0.975, test acc 0.889\n",
      "epoch: 3/6, loss 0.090, train acc 0.976, test acc 0.896\n",
      "epoch: 4/6, loss 0.086, train acc 0.977, test acc 0.896\n",
      "epoch: 5/6, loss 0.078, train acc 0.980, test acc 0.900\n",
      "epoch: 6/6, loss 0.076, train acc 0.979, test acc 0.899\n",
      "*** 440.9 examples/sec on [device(type='cuda', index=0)] - [0:00:03:44], all: [0:00:08:21] ***\n",
      "--- 5/5 ---\n",
      "training on: [device(type='cuda', index=0)], [2024-06-13 09:26:50]\n",
      "epoch: 1/6, loss 0.074, train acc 0.979, test acc 0.897\n",
      "epoch: 2/6, loss 0.070, train acc 0.982, test acc 0.893\n",
      "epoch: 3/6, loss 0.064, train acc 0.983, test acc 0.899\n",
      "epoch: 4/6, loss 0.063, train acc 0.984, test acc 0.899\n",
      "epoch: 5/6, loss 0.058, train acc 0.984, test acc 0.912\n",
      "epoch: 6/6, loss 0.058, train acc 0.983, test acc 0.905\n",
      "*** 447.2 examples/sec on [device(type='cuda', index=0)] - [0:00:03:41], all: [0:00:08:17] ***\n"
     ]
    }
   ],
   "source": [
    "train_times = 5\n",
    "for i in range(train_times):\n",
    "    print(f'--- {i+1}/{train_times} ---')\n",
    "    # 训练模型\n",
    "    train_fine_tuning(net, learning_rate=5e-5, batch_size=128, num_epochs=6, \n",
    "                      weight_decay=1e-3, fc_lr_times=10)\n",
    "    # 保存训练好的模型weight\n",
    "    save_model_path = Path(fr'../data/leaves_resnet34_state_dict_{i+1}.sd')\n",
    "    torch.save(net.state_dict(), save_model_path.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a01ea56-cf1e-448e-9cc3-da638781595b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on: [device(type='cuda', index=0)], [2024-06-13 09:56:26]\n",
      "epoch: 1/10, loss 0.044, train acc 0.989, test acc 0.912\n",
      "epoch: 2/10, loss 0.046, train acc 0.988, test acc 0.905\n",
      "epoch: 3/10, loss 0.043, train acc 0.989, test acc 0.910\n",
      "epoch: 4/10, loss 0.044, train acc 0.988, test acc 0.911\n",
      "epoch: 5/10, loss 0.042, train acc 0.989, test acc 0.904\n",
      "epoch: 6/10, loss 0.043, train acc 0.988, test acc 0.904\n",
      "epoch: 7/10, loss 0.043, train acc 0.989, test acc 0.901\n",
      "epoch: 8/10, loss 0.043, train acc 0.988, test acc 0.908\n",
      "epoch: 9/10, loss 0.043, train acc 0.987, test acc 0.910\n",
      "epoch: 10/10, loss 0.041, train acc 0.989, test acc 0.911\n",
      "*** 445.1 examples/sec on [device(type='cuda', index=0)] - [0:00:06:11], all: [0:00:13:47] ***\n"
     ]
    }
   ],
   "source": [
    "# 调整学习率、权重衰减等参数，多次学习调整\n",
    "train_fine_tuning(net, learning_rate=1e-5, batch_size=128, num_epochs=10, \n",
    "                  weight_decay=1e-2, fc_lr_times=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c36a7675-f8e6-4520-b49c-17651e74112f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on: [device(type='cuda', index=0)], [2024-06-13 10:10:22]\n",
      "epoch: 1/10, loss 0.067, train acc 0.980, test acc 0.000\n",
      "epoch: 2/10, loss 0.065, train acc 0.982, test acc 0.000\n",
      "epoch: 3/10, loss 0.061, train acc 0.982, test acc 0.000\n",
      "epoch: 4/10, loss 0.062, train acc 0.981, test acc 0.000\n",
      "epoch: 5/10, loss 0.062, train acc 0.982, test acc 0.000\n",
      "epoch: 6/10, loss 0.061, train acc 0.982, test acc 0.000\n",
      "epoch: 7/10, loss 0.057, train acc 0.983, test acc 0.000\n",
      "epoch: 8/10, loss 0.056, train acc 0.984, test acc 0.000\n",
      "epoch: 9/10, loss 0.054, train acc 0.985, test acc 0.000\n",
      "epoch: 10/10, loss 0.054, train acc 0.984, test acc 0.000\n",
      "*** 444.6 examples/sec on [device(type='cuda', index=0)] - [0:00:06:52], all: [0:00:14:10] ***\n"
     ]
    }
   ],
   "source": [
    "# 训练所有数据\n",
    "train_fine_tuning(net, learning_rate=1e-5, batch_size=128, num_epochs=10, \n",
    "                  weight_decay=2e-3, fc_lr_times=10, train_all_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a40ac54-3c33-47af-a959-8202c5968821",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i = 6\n",
    "save_model_path = Path(fr'../data/resnet34_state_dict_{model_i}.sd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fb1db3e-1239-4073-81c3-85215eaed65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存训练好的模型weight\n",
    "torch.save(net.state_dict(), save_model_path.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4e1779b-a792-44ba-8ce9-8c9fbba48a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (relu2): ReLU(inplace=True)\n",
       "  (fc2): Linear(in_features=512, out_features=176, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载训练好的模型\n",
    "net = None\n",
    "devices = utils.try_all_gpus()\n",
    "# 加载模型参数state_dict\n",
    "net = torchvision.models.resnet34()\n",
    "# 自定义fc层，将最终的输出类别设置为当前需要的176\n",
    "net.fc = nn.Linear(net.fc.in_features, 512)\n",
    "net.add_module('relu2', nn.ReLU(inplace=True))\n",
    "net.add_module('fc2', nn.Linear(512, 176))\n",
    "net.load_state_dict(torch.load(save_model_path.as_posix()))\n",
    "# net.to(torch.device('cpu'))\n",
    "net.to(devices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3836098f-0208-4e5f-a314-64d5c111f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "test_iter = torch.utils.data.DataLoader(leaves_dataset_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb1860c9-ba68-43d6-887f-bbc1e700e006",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = torch.Tensor([], device=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f96bc00c-e58a-41d2-b973-4e3878d451e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 torch.Size([8800])\r"
     ]
    }
   ],
   "source": [
    "for i, X in enumerate(test_iter):\n",
    "    # X = X.to(torch.device('cpu'))\n",
    "    X = X.to(devices[0])\n",
    "    y_hat = net(X)\n",
    "    y_hat = y_hat.to(torch.device('cpu'))\n",
    "    y_hat = y_hat.argmax(axis=1)\n",
    "    y_all = torch.cat([y_all, y_hat], dim=0)\n",
    "    print(i, y_all.shape, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0de7ae42-148d-49dc-ac79-99b0a53a913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping_path = data_dir / 'class_mapping.json'\n",
    "class_mapping_dict = dict()\n",
    "with open(class_mapping_path.as_posix(), 'r', encoding='utf8') as fp:\n",
    "    class_mapping_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8199cb97-7cf7-4246-b049-c0d559d9b3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  7.,  58., 136.,  51.,  58.,  20., 104., 110.,   9.,  50.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1760f39d-0044-4287-bf04-b948cf5f805a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  7,  58, 136,  51,  58,  20, 104, 110,   9,  50], dtype=torch.int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all = y_all.type(torch.int)\n",
    "y_all[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b3a62d9-fcf1-4df8-8547-ec4869399176",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all_mapping_list = list()\n",
    "for i in y_all:\n",
    "    i_num = i.item()\n",
    "    i_mapping = class_mapping_dict.get(str(i_num))\n",
    "    y_all_mapping_list.append(i_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51d1535e-2861-4284-8888-5306a5421fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8800"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_all_mapping_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d0aa758-3aea-497f-a76b-f6e0b9405a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8800, ['images/18353.jpg'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(leaves_dataset_test.data_list), leaves_dataset_test.data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "feeebe6e-ff17-4b3b-ad20-f69a2e342a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8800, 'images/18353.jpg')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path_list = [i[0] for i in leaves_dataset_test.data_list]\n",
    "len(image_path_list), image_path_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e554f1fb-8c3e-4538-bffe-25c2cee3eadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data = {\n",
    "    'image': image_path_list,\n",
    "    'label': y_all_mapping_list\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "654372ce-2214-49bb-b49c-1d88bdc86b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/18353.jpg</td>\n",
       "      <td>asimina_triloba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/18354.jpg</td>\n",
       "      <td>platanus_occidentalis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/18355.jpg</td>\n",
       "      <td>platanus_acerifolia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/18356.jpg</td>\n",
       "      <td>pinus_bungeana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/18357.jpg</td>\n",
       "      <td>platanus_occidentalis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              image                  label\n",
       "0  images/18353.jpg        asimina_triloba\n",
       "1  images/18354.jpg  platanus_occidentalis\n",
       "2  images/18355.jpg    platanus_acerifolia\n",
       "3  images/18356.jpg         pinus_bungeana\n",
       "4  images/18357.jpg  platanus_occidentalis"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df = pd.DataFrame(submission_data)\n",
    "y_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44c26a78-00c4-4fd7-b57f-4c1ae24e1822",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df.to_csv((data_dir / 'submission.csv').as_posix(), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0add4584-fa50-4737-802d-033135ba7f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
