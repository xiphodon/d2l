{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2af9ea4e-738b-4b9b-8ecb-a5ac25cef15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import utils\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c45f5d52-d4cb-46e9-a078-f552ac110d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(r'../data/classify-leaves')\n",
    "data_csv_train = data_dir / 'train.csv'\n",
    "data_csv_test = data_dir / 'test.csv'\n",
    "data_images = data_dir / 'images'\n",
    "resnet34_state_dict_path = Path('../data/resnet34_state_dict.sd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a31a3532-4319-439b-890d-60f0bb31cf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeavesDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "        树叶数据集\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir: Path, data_csv: Path, transforms=None, is_train=True):\n",
    "        \"\"\"\n",
    "            data_dir: 数据集目录\n",
    "            data_csv: 数据-类对应文件\n",
    "            transforms：数据增广\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.data_csv = data_csv\n",
    "        self.class_mapping_path = data_dir / 'class_mapping.json'\n",
    "        self.transforms = transforms\n",
    "        self.is_train = is_train\n",
    "        self.class_mapping_dict = dict()\n",
    "        self.data_list = self.read_data()\n",
    "        \n",
    "    def read_data(self):\n",
    "        \"\"\"\n",
    "            读取数据\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(self.data_csv.as_posix())\n",
    "        if not self.class_mapping_path.exists():\n",
    "            unique_labels = df['label'].unique() \n",
    "            for i, class_name in enumerate(unique_labels):\n",
    "                self.class_mapping_dict[str(i)] = class_name\n",
    "                self.class_mapping_dict[class_name] = i\n",
    "            with open(self.class_mapping_path.as_posix(), 'w', encoding='utf8') as fp:\n",
    "                json.dump(self.class_mapping_dict, fp)\n",
    "        else:\n",
    "            with open(self.class_mapping_path.as_posix(), 'r', encoding='utf8') as fp:\n",
    "                self.class_mapping_dict = json.load(fp)\n",
    "        return df.values.tolist()\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # print(self.data_list[i])\n",
    "        if self.is_train:\n",
    "            _img_path, label = self.data_list[i]\n",
    "        else:\n",
    "            _img_path = self.data_list[i]\n",
    "            if isinstance(_img_path, list):\n",
    "                _img_path = _img_path[0]\n",
    "        img_path = self.data_dir / _img_path\n",
    "        img = Image.open(img_path.as_posix()).convert('RGB')\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "        return (img, self.class_mapping_dict[label]) if self.is_train else img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "163b2844-23be-4fd2-9652-52a07b34957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用RGB通道的均值和标准差，以标准化每个通道\n",
    "normalize = torchvision.transforms.Normalize(\n",
    "    [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "train_augs = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop(224),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    normalize])\n",
    "\n",
    "test_augs = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize([224, 224]),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc8d60a-a9fe-411c-967a-53f6fc4442be",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaves_dataset_train = LeavesDataset(data_dir, data_csv_train, transforms=train_augs)\n",
    "leaves_dataset_test = LeavesDataset(data_dir, data_csv_test, transforms=test_augs, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1575e68-7eab-4f86-b61f-bba79058c9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_len = int(0.75 * len(leaves_dataset_train))\n",
    "test_dataset_len = len(leaves_dataset_train) - train_dataset_len\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset=leaves_dataset_train,\n",
    "    lengths=[train_dataset_len, test_dataset_len],\n",
    "    generator=torch.Generator().manual_seed(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ca57890-ac06-4a78-a55d-b99b176979ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_net = torchvision.models.resnet34(pretrained=True)\n",
    "pretrained_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0ca21f1-2694-4a68-8311-f8a21dcf4a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_net.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f91fcf37-bbbf-4c0e-8498-21682ef5a502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=176, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 变更最后一层fc，将输出类别设置为当前需要的176\n",
    "pretrained_net.fc = nn.Linear(pretrained_net.fc.in_features, 176)\n",
    "nn.init.xavier_uniform_(pretrained_net.fc.weight);\n",
    "pretrained_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dab02605-c6e7-4dce-a02c-db630e0d78b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果param_group=True，输出层中的模型参数将使用十倍的学习率\n",
    "def train_fine_tuning(net, learning_rate, batch_size=128, num_epochs=5, param_group=True, freeze=True):\n",
    "    train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "    devices = utils.try_all_gpus()\n",
    "    loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "    if freeze:\n",
    "        for name, param in net.named_parameters():\n",
    "            if name not in [\"fc.weight\", \"fc.bias\"]:\n",
    "                param.requires_grad = False\n",
    "    if param_group:\n",
    "        params_1x = [param for name, param in net.named_parameters()\n",
    "             if name not in [\"fc.weight\", \"fc.bias\"]]\n",
    "        trainer = torch.optim.SGD(\n",
    "            [\n",
    "                {'params': params_1x}, \n",
    "                {'params': net.fc.parameters(), \n",
    "                 'lr': learning_rate * 20}\n",
    "            ], \n",
    "            lr=learning_rate, \n",
    "            weight_decay=0.001\n",
    "        )\n",
    "    else:\n",
    "        trainer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=0.001)\n",
    "    utils.train_gpus(net, train_iter, test_iter, loss, trainer, num_epochs, devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a01ea56-cf1e-448e-9cc3-da638781595b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/20, loss 3.931, train acc 0.180, test acc 0.381\n",
      "epoch: 2/20, loss 2.172, train acc 0.463, test acc 0.516\n",
      "epoch: 3/20, loss 1.627, train acc 0.583, test acc 0.587\n",
      "epoch: 4/20, loss 1.333, train acc 0.650, test acc 0.652\n",
      "epoch: 5/20, loss 1.150, train acc 0.702, test acc 0.692\n",
      "epoch: 6/20, loss 1.042, train acc 0.729, test acc 0.715\n",
      "epoch: 7/20, loss 0.952, train acc 0.751, test acc 0.732\n",
      "epoch: 8/20, loss 0.873, train acc 0.770, test acc 0.753\n",
      "epoch: 9/20, loss 0.830, train acc 0.780, test acc 0.753\n",
      "epoch: 10/20, loss 0.752, train acc 0.802, test acc 0.763\n",
      "epoch: 11/20, loss 0.694, train acc 0.819, test acc 0.772\n",
      "epoch: 12/20, loss 0.698, train acc 0.814, test acc 0.790\n",
      "epoch: 13/20, loss 0.680, train acc 0.822, test acc 0.800\n",
      "epoch: 14/20, loss 0.643, train acc 0.833, test acc 0.806\n",
      "epoch: 15/20, loss 0.598, train acc 0.841, test acc 0.796\n",
      "epoch: 16/20, loss 0.588, train acc 0.846, test acc 0.808\n",
      "epoch: 17/20, loss 0.570, train acc 0.853, test acc 0.805\n",
      "epoch: 18/20, loss 0.557, train acc 0.854, test acc 0.815\n",
      "epoch: 19/20, loss 0.526, train acc 0.862, test acc 0.827\n",
      "epoch: 20/20, loss 0.518, train acc 0.864, test acc 0.815\n",
      "*** 125.5 examples/sec on [device(type='cuda', index=0)] - [0:00:36:34], all: [0:01:02:41] ***\n"
     ]
    }
   ],
   "source": [
    "train_fine_tuning(pretrained_net, learning_rate=5e-5, batch_size=64, num_epochs=20, freeze=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fb1db3e-1239-4073-81c3-85215eaed65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存训练好的模型weight\n",
    "torch.save(pretrained_net.state_dict(), resnet34_state_dict_path.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3836098f-0208-4e5f-a314-64d5c111f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练好的模型\n",
    "pretrained_net = None\n",
    "devices = utils.try_all_gpus()\n",
    "# 加载模型参数state_dict\n",
    "net = torchvision.models.resnet34()\n",
    "# 变更最后一层fc，将输出类别设置为当前需要的176\n",
    "net.fc = nn.Linear(net.fc.in_features, 176)\n",
    "net.load_state_dict(torch.load(resnet34_state_dict_path.as_posix()))\n",
    "# net.to(torch.device('cpu'))\n",
    "net.to(devices[0])\n",
    "net.eval()\n",
    "\n",
    "test_iter = torch.utils.data.DataLoader(leaves_dataset_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb1860c9-ba68-43d6-887f-bbc1e700e006",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = torch.Tensor([], device=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f96bc00c-e58a-41d2-b973-4e3878d451e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274 torch.Size([8800])\r"
     ]
    }
   ],
   "source": [
    "for i, X in enumerate(test_iter):\n",
    "    # X = X.to(torch.device('cpu'))\n",
    "    X = X.to(devices[0])\n",
    "    y_hat = net(X)\n",
    "    y_hat = y_hat.argmax(axis=1)\n",
    "    y_hat = y_hat.to(torch.device('cpu'))\n",
    "    y_all = torch.cat([y_all, y_hat], dim=0)\n",
    "    print(i, y_all.shape, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0de7ae42-148d-49dc-ac79-99b0a53a913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping_path = data_dir / 'class_mapping.json'\n",
    "class_mapping_dict = dict()\n",
    "with open(class_mapping_path.as_posix(), 'r', encoding='utf8') as fp:\n",
    "    class_mapping_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8199cb97-7cf7-4246-b049-c0d559d9b3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  7.,  96., 136.,  51.,  58.,  20., 104., 110.,   9.,  50.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1760f39d-0044-4287-bf04-b948cf5f805a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  7,  96, 136,  51,  58,  20, 104, 110,   9,  50], dtype=torch.int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all = y_all.type(torch.int)\n",
    "y_all[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b3a62d9-fcf1-4df8-8547-ec4869399176",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all_mapping_list = list()\n",
    "for i in y_all:\n",
    "    i_num = i.item()\n",
    "    i_mapping = class_mapping_dict.get(str(i_num))\n",
    "    y_all_mapping_list.append(i_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51d1535e-2861-4284-8888-5306a5421fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8800"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_all_mapping_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d0aa758-3aea-497f-a76b-f6e0b9405a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8800, ['images/18353.jpg'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(leaves_dataset_test.data_list), leaves_dataset_test.data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "feeebe6e-ff17-4b3b-ad20-f69a2e342a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8800, 'images/18353.jpg')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path_list = [i[0] for i in leaves_dataset_test.data_list]\n",
    "len(image_path_list), image_path_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e554f1fb-8c3e-4538-bffe-25c2cee3eadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data = {\n",
    "    'image': image_path_list,\n",
    "    'label': y_all_mapping_list\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "654372ce-2214-49bb-b49c-1d88bdc86b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/18353.jpg</td>\n",
       "      <td>asimina_triloba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/18354.jpg</td>\n",
       "      <td>populus_grandidentata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/18355.jpg</td>\n",
       "      <td>platanus_acerifolia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/18356.jpg</td>\n",
       "      <td>pinus_bungeana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/18357.jpg</td>\n",
       "      <td>platanus_occidentalis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              image                  label\n",
       "0  images/18353.jpg        asimina_triloba\n",
       "1  images/18354.jpg  populus_grandidentata\n",
       "2  images/18355.jpg    platanus_acerifolia\n",
       "3  images/18356.jpg         pinus_bungeana\n",
       "4  images/18357.jpg  platanus_occidentalis"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df = pd.DataFrame(submission_data)\n",
    "y_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44c26a78-00c4-4fd7-b57f-4c1ae24e1822",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df.to_csv((data_dir / 'submission.csv').as_posix(), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0add4584-fa50-4737-802d-033135ba7f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
